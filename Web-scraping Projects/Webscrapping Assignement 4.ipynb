{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0827be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654a0b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****STARTING WEBSCRAPPING ASSIGNMENT 4*******\n"
     ]
    }
   ],
   "source": [
    "print (\"****STARTING WEBSCRAPPING ASSIGNMENT 4*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c39d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******QUESTION NO 1*******\n"
     ]
    }
   ],
   "source": [
    "print (\"******QUESTION NO 1*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5797f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65bfa960",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a98dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c89f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed70b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    2.                                   \"Despacito\"[7]   \n",
      "1    3.                       \"Johny Johny Yes Papa\"[14]   \n",
      "2    4.                                  \"Bath Song\"[15]   \n",
      "3    5.                               \"Shape of You\"[16]   \n",
      "4    6.                              \"See You Again\"[18]   \n",
      "5    7.                \"Phonics Song with Two Words\"[23]   \n",
      "6    8.                          \"Wheels on the Bus\"[24]   \n",
      "7    9.                                \"Uptown Funk\"[25]   \n",
      "8   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
      "9   11.                              \"Gangnam Style\"[27]   \n",
      "10  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
      "11  13.                             \"Dame Tu Cosita\"[33]   \n",
      "12  14.                                     \"Axel F\"[34]   \n",
      "13  15.                                      \"Sugar\"[35]   \n",
      "14  16.                                       \"Roar\"[36]   \n",
      "15  17.                             \"Counting Stars\"[37]   \n",
      "16  18.                                      \"Sorry\"[38]   \n",
      "17  19.                        \"Baa Baa Black Sheep\"[39]   \n",
      "18  20.                          \"Thinking Out Loud\"[40]   \n",
      "19  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
      "20  22.                                 \"Dark Horse\"[42]   \n",
      "21  23.                                      \"Faded\"[43]   \n",
      "22  24.                                    \"Perfect\"[44]   \n",
      "23  25.                             \"Lakdi Ki Kathi\"[45]   \n",
      "24  26.                                 \"Let Her Go\"[46]   \n",
      "25  27.                             \"Girls Like You\"[47]   \n",
      "26  28.          \"Humpty the train on a fruits ride\"[48]   \n",
      "27  29.                                    \"Lean On\"[49]   \n",
      "28  30.                                   \"Bailando\"[50]   \n",
      "\n",
      "                                           Artist Upload Date  \\\n",
      "0                                      Luis Fonsi        8.14   \n",
      "1                                     LooLoo Kids        6.69   \n",
      "2                      Cocomelon – Nursery Rhymes        6.15   \n",
      "3                                      Ed Sheeran        5.97   \n",
      "4                                     Wiz Khalifa        5.86   \n",
      "5                                       ChuChu TV        5.26   \n",
      "6                      Cocomelon – Nursery Rhymes        5.14   \n",
      "7                                     Mark Ronson        4.89   \n",
      "8                                     Miroshka TV        4.87   \n",
      "9                                             Psy        4.77   \n",
      "10                                     Get Movies        4.55   \n",
      "11                                      El Chombo        4.32   \n",
      "12                                     Crazy Frog        3.87   \n",
      "13                                       Maroon 5        3.86   \n",
      "14                                     Katy Perry        3.78   \n",
      "15                                    OneRepublic        3.77   \n",
      "16                                  Justin Bieber        3.65   \n",
      "17                     Cocomelon – Nursery Rhymes        3.61   \n",
      "18                                     Ed Sheeran        3.58   \n",
      "19                                        Shakira        3.56   \n",
      "20                                     Katy Perry        3.50   \n",
      "21                                    Alan Walker        3.44   \n",
      "22                                     Ed Sheeran        3.42   \n",
      "23                                   Jingle Toons        3.42   \n",
      "24                                      Passenger        3.42   \n",
      "25                                       Maroon 5        3.40   \n",
      "26  Kiddiestv Hindi – Nursery Rhymes & Kids Songs        3.38   \n",
      "27                                    Major Lazer        3.37   \n",
      "28                               Enrique Iglesias        3.37   \n",
      "\n",
      "                Views  \n",
      "0    January 12, 2017  \n",
      "1     October 8, 2016  \n",
      "2         May 2, 2018  \n",
      "3    January 30, 2017  \n",
      "4       April 6, 2015  \n",
      "5       March 6, 2014  \n",
      "6        May 24, 2018  \n",
      "7   November 19, 2014  \n",
      "8   February 27, 2018  \n",
      "9       July 15, 2012  \n",
      "10   January 31, 2012  \n",
      "11      April 5, 2018  \n",
      "12      June 16, 2009  \n",
      "13   January 14, 2015  \n",
      "14  September 5, 2013  \n",
      "15       May 31, 2013  \n",
      "16   October 22, 2015  \n",
      "17      June 25, 2018  \n",
      "18    October 7, 2014  \n",
      "19       June 4, 2010  \n",
      "20  February 20, 2014  \n",
      "21   December 3, 2015  \n",
      "22   November 9, 2017  \n",
      "23      June 14, 2018  \n",
      "24      July 25, 2012  \n",
      "25       May 31, 2018  \n",
      "26   January 26, 2018  \n",
      "27     March 22, 2015  \n",
      "28     April 11, 2014  \n"
     ]
    }
   ],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "service = Service('path_to_chromedriver')\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"wikitable sortable jquery-tablesorter\"]')\n",
    "\n",
    "rank_element = []\n",
    "name_element = []\n",
    "artist_element = []\n",
    "upload_date_element = []\n",
    "views_element = []\n",
    "\n",
    "rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_elements(By.XPATH, \".//td\")\n",
    "\n",
    "    if len(columns) >= 5:\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].text.strip()\n",
    "        artist = columns[2].text.strip()\n",
    "        upload_date = columns[3].text.strip()\n",
    "        views = columns[4].text.strip()\n",
    "\n",
    "    rank_element.append(rank)\n",
    "    name_element.append(name)\n",
    "    artist_element.append(artist)\n",
    "    upload_date_element.append(upload_date)\n",
    "    views_element.append(views)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data = {\n",
    "    'Rank': rank_list,\n",
    "    'Name': name_list,\n",
    "    'Artist': artist_list,\n",
    "    'Upload Date': upload_date_list,\n",
    "    'Views': views_list\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb5fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****END OF QUESTION N0.1*********\n"
     ]
    }
   ],
   "source": [
    "print (\"*****END OF QUESTION N0.1*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "415d49dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******QUESTION N0.2*********\n"
     ]
    }
   ],
   "source": [
    "print (\"*******QUESTION N0.2*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fb3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ceebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/international/fixtures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dc4d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_click=driver.find_element(By.XPATH, '//span[@class=\"menu-icon__line\"]')\n",
    "button_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f7dfbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_click=driver.find_element(By.XPATH, '//a[@class=\"nav-link \"]')\n",
    "select_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da6a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8a14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf7feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_title = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ae3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    match_title_element = driver.find_element(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    match_title.append(match_title_element.text)\n",
    "except NoSuchElementException:\n",
    "    match_title.append('N/A')\n",
    "\n",
    "try:\n",
    "    series_element = driver.find_element(By.XPATH, '//img[@class=\"igm-fluid ng-scope\"]')\n",
    "    series.append(series_element.text)\n",
    "except NoSuchElementException:\n",
    "    series.append('N/A')\n",
    "\n",
    "try:\n",
    "    place_element = driver.find_element(By.XPATH, '//span[@class=\"ng-binding\"]')\n",
    "    place.append(place_element.text)\n",
    "except NoSuchElementException:\n",
    "    place.append('N/A')\n",
    "\n",
    "try:\n",
    "    date_element = driver.find_element(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "    date.append(date_element.text)\n",
    "except NoSuchElementException:\n",
    "    date.append('N/A')\n",
    "\n",
    "try:\n",
    "    time_element = driver.find_element(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    time.append(time_element.text)\n",
    "except NoSuchElementException:\n",
    "    time.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4553f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Match Title Series   Place        Date  \\\n",
      "0  ICC WORLD TEST CHAMPIONSHIP FINAL 2023         London  7 JUN 2023   \n",
      "\n",
      "          Time  \n",
      "0  3:30 PM IST  \n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Match Title': match_title,\n",
    "    'Series': series,\n",
    "    'Place': place,\n",
    "    'Date': date,\n",
    "    'Time': time\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c6de24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************QUESTION 2 complete**********, only one match is being displayed presently in international category\n"
     ]
    }
   ],
   "source": [
    "print(\"****************QUESTION 2 complete**********, only one match is being displayed presently in international category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5e742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************QUESTION NO 3*************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************QUESTION NO 3*************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "116a21aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c93b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38079a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_click=driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]')\n",
    "dropdown_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b7459b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_click=driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "select_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e0e26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newselect_click=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "newselect_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fb42207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping row with insufficient data\n"
     ]
    }
   ],
   "source": [
    "table = driver.find_element(By.CLASS_NAME, 'display')\n",
    "\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows[1:]:\n",
    "    columns = row.find_elements(By.TAG_NAME, 'td')\n",
    "    \n",
    "    \n",
    "    if len(columns) >= 6:\n",
    "        \n",
    "        item = {\n",
    "            'Rank': columns[0].text,\n",
    "            'State': columns[1].text,\n",
    "            'GSDP(18-19)- at current prices': columns[2].text,\n",
    "            'GSDP(19-20)- at current prices': columns[3].text,\n",
    "            'Share(18-19)': columns[4].text,\n",
    "            'GDP($ billion)': columns[5].text\n",
    "        }\n",
    "    \n",
    "        \n",
    "        data.append(item)\n",
    "    else:\n",
    "        print(\"Skipping row with insufficient data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1fee69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(18-19)- at current prices GSDP(19-20)- at current prices Share(18-19) GDP($ billion)\n",
      "0     1                Maharashtra                              -                      2,632,792       13.94%        399.921\n",
      "1     2                 Tamil Nadu                      1,845,853                      1,630,208        8.63%        247.629\n",
      "2     3              Uttar Pradesh                      1,687,818                      1,584,764        8.39%        240.726\n",
      "3     4                    Gujarat                              -                      1,502,899        7.96%        228.290\n",
      "4     5                  Karnataka                      1,631,977                      1,493,127        7.91%        226.806\n",
      "5     6                West Bengal                      1,253,832                      1,089,898        5.77%        165.556\n",
      "6     7                  Rajasthan                      1,020,989                        942,586        4.99%        143.179\n",
      "7     8             Andhra Pradesh                        972,782                        862,957        4.57%        131.083\n",
      "8     9                  Telangana                        969,604                        861,031        4.56%        130.791\n",
      "9    10             Madhya Pradesh                        906,672                        809,592        4.29%        122.977\n",
      "10   11                     Kerala                              -                        781,653        4.14%        118.733\n",
      "11   12                      Delhi                        856,112                        774,870        4.10%        117.703\n",
      "12   13                    Haryana                        831,610                        734,163        3.89%        111.519\n",
      "13   14                      Bihar                        611,804                        530,363        2.81%         80.562\n",
      "14   15                     Punjab                        574,760                        526,376        2.79%         79.957\n",
      "15   16                     Odisha                        521,275                        487,805        2.58%         74.098\n",
      "16   17                      Assam                              -                        315,881        1.67%         47.982\n",
      "17   18               Chhattisgarh                        329,180                        304,063        1.61%         46.187\n",
      "18   19                  Jharkhand                        328,598                        297,204        1.57%         45.145\n",
      "19   20                Uttarakhand                              -                        245,895        1.30%         37.351\n",
      "20   21            Jammu & Kashmir                              -                        155,956        0.83%         23.690\n",
      "21   22           Himachal Pradesh                        165,472                        153,845        0.81%         23.369\n",
      "22   23                        Goa                         80,449                         73,170        0.39%         11.115\n",
      "23   24                    Tripura                         55,984                         49,845        0.26%          7.571\n",
      "24   25                 Chandigarh                              -                         42,114        0.22%          6.397\n",
      "25   26                 Puducherry                         38,253                         34,433        0.18%          5.230\n",
      "26   27                  Meghalaya                         36,572                         33,481        0.18%          5.086\n",
      "27   28                     Sikkim                         32,496                         28,723        0.15%          4.363\n",
      "28   29                    Manipur                         31,790                         27,870        0.15%          4.233\n",
      "29   30                   Nagaland                              -                         27,283        0.14%          4.144\n",
      "30   31          Arunachal Pradesh                              -                         24,603        0.13%          3.737\n",
      "31   32                    Mizoram                         26,503                         22,287        0.12%          3.385\n",
      "32   33  Andaman & Nicobar Islands                              -                              -            -              -\n",
      "33                           India                     20,351,013                     18,886,957                       2,869\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f891635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********END OF QUESTION 3 WITH DESIRED OUTPUT***************\n"
     ]
    }
   ],
   "source": [
    "print(\"***********END OF QUESTION 3 WITH DESIRED OUTPUT***************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78e7b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** QUESTION 4 *************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********** QUESTION 4 *************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f939ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d521dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "552af23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/div/div[1]/div/div/form/label/input[1]')\n",
    "search_bar.send_keys('trending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b492a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2806184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4dd17d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Repository Title  \\\n",
      "0        iam-abbas/Reddit-Stock-Trends   \n",
      "1                GeneralMills/pytrends   \n",
      "2       vitalets/github-trending-repos   \n",
      "3       mbadry1/Trending-Deep-Learning   \n",
      "4                    QasimWani/LeetHub   \n",
      "5         datawrangling/trendingtopics   \n",
      "6                                d3/d3   \n",
      "7         huchenme/github-trending-api   \n",
      "8  mitchelljy/Trending-YouTube-Scraper   \n",
      "9               Nightonke/GithubWidget   \n",
      "\n",
      "                              Repository Description Contributors Count  \\\n",
      "0          Fetch currently trending stocks on Reddit               1.5k   \n",
      "1                       Pseudo API for Google Trends               2.7k   \n",
      "2  Track GitHub trending repositories in your fav...               2.5k   \n",
      "3  Top 100 trending deep learning repositories so...                588   \n",
      "4  Automatically sync your leetcode solutions to ...               3.2k   \n",
      "5  Rails app for tracking trends in server logs -...                353   \n",
      "6  Bring data to life with SVG, Canvas and HTML. ...               105k   \n",
      "7  The missing APIs for GitHub trending projects ...                716   \n",
      "8  Python script that scrapes the currently trend...                238   \n",
      "9  Contributions, stars, followers, trending etc....                696   \n",
      "\n",
      "  Language Used  \n",
      "0        Python  \n",
      "1           N/A  \n",
      "2           N/A  \n",
      "3           N/A  \n",
      "4           N/A  \n",
      "5           N/A  \n",
      "6           N/A  \n",
      "7           N/A  \n",
      "8           N/A  \n",
      "9           N/A  \n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 1\n",
    "\n",
    "repository_titles = []\n",
    "repository_descriptions = []\n",
    "contributors_counts = []\n",
    "language_used = []\n",
    "\n",
    "for page in range(start, end):\n",
    "    try:\n",
    "        driver.get(\"https://github.com/search?q=trending&page=\" + str(page))\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//a[@class=\"v-align-middle\"]')))\n",
    "        repository_title_elements = driver.find_elements(By.XPATH, '//a[@class=\"v-align-middle\"]')\n",
    "        for element in repository_title_elements:\n",
    "            repository_titles.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        repository_titles.append('N/A')\n",
    "\n",
    "    try:\n",
    "        repository_desc_elements = driver.find_elements(By.XPATH, '//p[@class=\"mb-1\"]')\n",
    "        for element in repository_desc_elements:\n",
    "            repository_descriptions.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        repository_descriptions.append('N/A')\n",
    "\n",
    "    try:\n",
    "        contributors_count_elements = driver.find_elements(By.XPATH, '//a[@class=\"Link--muted\"]')\n",
    "        for element in contributors_count_elements:\n",
    "            contributors_counts.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        contributors_counts.append('N/A')\n",
    "\n",
    "    try:\n",
    "        language_used_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/div[4]/main/div/div[3]/div/ul/li[1]/div[2]/div[2]/div/div[2]/span')\n",
    "        for element in language_used_elements:\n",
    "            language_used.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        language_used.append('N/A')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    max_len = max(len(repository_titles), len(repository_descriptions), len(contributors_counts), len(language_used))\n",
    "    repository_titles += ['N/A'] * (max_len - len(repository_titles))\n",
    "    repository_descriptions += ['N/A'] * (max_len - len(repository_descriptions))\n",
    "    contributors_counts += ['N/A'] * (max_len - len(contributors_counts))\n",
    "    language_used += ['N/A'] * (max_len - len(language_used))\n",
    "\n",
    "#making data frame\n",
    "\n",
    "data = {\n",
    "    'Repository Title': repository_titles,\n",
    "    'Repository Description': repository_descriptions,\n",
    "    'Contributors Count': contributors_counts,\n",
    "    'Language Used': language_used\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bfb2097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******END OF QUESTION 4*************, only scraped data from page one\n"
     ]
    }
   ],
   "source": [
    "print (\"*******END OF QUESTION 4*************, only scraped data from page one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e15b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******QUESTION 5**********\n"
     ]
    }
   ],
   "source": [
    "print (\"*******QUESTION 5**********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4582d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening web\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5847b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd974b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_button=driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts_button.click() #clicking charts button on the homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d812cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_charts=driver.find_element(By.XPATH, '//span[@class=\"c-span-wrap lrv-u-flex lrv-u-justify-content-center lrv-u-align-items-center u-height-76 lrv-u-background-color-brand-primary\"]')\n",
    "view_charts.click() #viewing top 100 chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "115eaae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Song Name                           Artist Name Last Week Rank  \\\n",
      "0           Flowers                           Miley Cyrus              3   \n",
      "1         Kill Bill                                   SZA                  \n",
      "2   Ella Baila Sola           Eslabon Armado X Peso Pluma              2   \n",
      "3         Calm Down                   Rema & Selena Gomez                  \n",
      "4          Creepin'  Metro Boomin, The Weeknd & 21 Savage              4   \n",
      "..              ...                                   ...            ...   \n",
      "95          I Heard            YoungBoy Never Broke Again                  \n",
      "96          Sunrise                         Morgan Wallen             41   \n",
      "97            Happy                                    NF                  \n",
      "98              N/A                                   N/A             53   \n",
      "99              N/A                                   N/A                  \n",
      "\n",
      "   Weeks on Board  \n",
      "0              18  \n",
      "1              23  \n",
      "2               9  \n",
      "3              37  \n",
      "4              24  \n",
      "..            ...  \n",
      "95              1  \n",
      "96             11  \n",
      "97              6  \n",
      "98            N/A  \n",
      "99            N/A  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 1\n",
    "\n",
    "Song_name = []\n",
    "Artist_name = []\n",
    "Last_week_rank = []\n",
    "Weeks_on_board = []\n",
    "\n",
    "# Scrape song names\n",
    "try:\n",
    "    song_name_elements = driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]//li[@class=\"lrv-u-width-100p\"]//li[1]//h3')\n",
    "    for element in song_name_elements:\n",
    "        Song_name.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Song_name.append('N/A')\n",
    "\n",
    "# Scrape artist names\n",
    "try:\n",
    "    art_name_elements = driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]//li[@class=\"lrv-u-width-100p\"]//li[1]//span')\n",
    "    for element in art_name_elements:\n",
    "        Artist_name.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Artist_name.append('N/A')\n",
    "\n",
    "# Scrape last week ranks\n",
    "try:\n",
    "    LWR_elements = driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]//li[@class=\"lrv-u-width-100p\"]//li[4]')\n",
    "    for element in LWR_elements:\n",
    "        Last_week_rank.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Last_week_rank.append('N/A')\n",
    "\n",
    "# Scrape weeks on board\n",
    "try:\n",
    "    WOB_elements = driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]//li[@class=\"lrv-u-width-100p\"]//li[6]')\n",
    "    for element in WOB_elements:\n",
    "        Weeks_on_board.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks_on_board.append('N/A')\n",
    "\n",
    "# Check lengths of lists and fill shorter lists with 'N/A'\n",
    "max_length = max(len(Song_name), len(Artist_name), len(Last_week_rank), len(Weeks_on_board))\n",
    "Song_name += ['N/A'] * (max_length - len(Song_name))\n",
    "Artist_name += ['N/A'] * (max_length - len(Artist_name))\n",
    "Last_week_rank += ['N/A'] * (max_length - len(Last_week_rank))\n",
    "Weeks_on_board += ['N/A'] * (max_length - len(Weeks_on_board))\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Song Name': Song_name,\n",
    "    'Artist Name': Artist_name,\n",
    "    'Last Week Rank': Last_week_rank,\n",
    "    'Weeks on Board': Weeks_on_board\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print (df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bc2dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******END OF QUESTION 5******\n"
     ]
    }
   ],
   "source": [
    "print (\"******END OF QUESTION 5******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f0bf8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******QUESTION 6******\n"
     ]
    }
   ],
   "source": [
    "print (\"******QUESTION 6******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c05fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data of top novels is present of the given link - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare\n"
     ]
    }
   ],
   "source": [
    "print (\"no data of top novels is present of the given link - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e81dccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******END OF QUESTION 6******\n"
     ]
    }
   ],
   "source": [
    "print (\"******END OF QUESTION 6******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd2134e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 7 - Scrape the details of the most watched TV series of all time from imdb.com.\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 7 - Scrape the details of the most watched TV series of all time from imdb.com.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b37fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the web\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "549da0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrape successfull\n"
     ]
    }
   ],
   "source": [
    "#scrape the data\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# Scrape names\n",
    "try:\n",
    "    i_name_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//h3//a')\n",
    "    for element in i_name_elements:\n",
    "        Name.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('N/A')\n",
    "\n",
    "# Scrape year span\n",
    "try:\n",
    "    year_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//h3//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    for element in year_elements:\n",
    "        Year_span.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Year_span.append('N/A')\n",
    "\n",
    "# Scrape Genre\n",
    "try:\n",
    "    genre_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//p//span[@class=\"genre\"]')\n",
    "    for element in genre_elements:\n",
    "        Genre.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('N/A')\n",
    "\n",
    "# Scrape Run time\n",
    "try:\n",
    "    rt_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//p//span[@class=\"runtime\"]')\n",
    "    for element in rt_elements:\n",
    "        Run_time.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Run_time.append('N/A')\n",
    "    \n",
    "    # Scrape Ratings\n",
    "try:\n",
    "    ratings_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//span[@class=\"ipl-rating-star__rating\"]')\n",
    "    for element in ratings_elements:\n",
    "        Ratings.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('N/A')\n",
    "    \n",
    "    # Scrape Votes\n",
    "try:\n",
    "    votes_elements = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]//span[@name=\"nv\"]')\n",
    "    for element in votes_elements:\n",
    "        Votes.append(element.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('N/A')\n",
    "    \n",
    "# Check lengths of lists and fill shorter lists with 'N/A'\n",
    "    \n",
    "max_length = max(len(Name), len(Year_span), len(Genre), len(Run_time), len(Ratings), len(Votes))\n",
    "Name += ['N/A'] * (max_length - len(Name))\n",
    "Year_span += ['N/A'] * (max_length - len(Year_span))\n",
    "Genre += ['N/A'] * (max_length - len(Genre))\n",
    "Run_time += ['N/A'] * (max_length - len(Run_time))\n",
    "Ratings += ['N/A'] * (max_length - len(Ratings))\n",
    "Votes += ['N/A'] * (max_length - len(Votes))\n",
    "\n",
    "    \n",
    "print(\"scrape successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c75b96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,163,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td></td>\n",
       "      <td>1,243,199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Rate</td>\n",
       "      <td>1,027,704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td></td>\n",
       "      <td>302,304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td></td>\n",
       "      <td>261,418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Year_span                     Genre Ratings      Votes\n",
       "0   Game of Thrones  (2011–2019)  Action, Adventure, Drama     9.2  2,163,377\n",
       "1   Stranger Things  (2016–2024)    Drama, Fantasy, Horror          1,243,199\n",
       "2  The Walking Dead  (2010–2022)   Drama, Horror, Thriller    Rate  1,027,704\n",
       "3    13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller            302,304\n",
       "4           The 100  (2014–2020)    Drama, Mystery, Sci-Fi            261,418"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make data frame and print the result\n",
    "pd.DataFrame({'Name':Name,'Year_span':Year_span,'Genre':Genre,'Ratings':Ratings,'Votes':Votes}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d0607ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****END OF QUESTION 7******\n"
     ]
    }
   ],
   "source": [
    "print (\"*****END OF QUESTION 7******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dce6365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF QUESTION 8 - Details of Datasets from UCI machine learning repositories - Url = https://archive.ics.uci.edu/\n"
     ]
    }
   ],
   "source": [
    "print (\"END OF QUESTION 8 - Details of Datasets from UCI machine learning repositories - Url = https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dce94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open web\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72c8817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting desired button\n",
    "select=driver.find_element(By.XPATH, '//span[@class=\"whitetext\"][2]//a[1]')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "796d8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Dataset Name Data Type                          Task  \\\n",
      "0                         Abalone                                 Abalone   \n",
      "1                           Adult                                   Adult   \n",
      "2                       Annealing                               Annealing   \n",
      "3    Anonymous Microsoft Web Data            Anonymous Microsoft Web Data   \n",
      "4                      Arrhythmia                              Arrhythmia   \n",
      "5           Artificial Characters                   Artificial Characters   \n",
      "6            Audiology (Original)                    Audiology (Original)   \n",
      "7        Audiology (Standardized)                Audiology (Standardized)   \n",
      "8                        Auto MPG                                Auto MPG   \n",
      "9                      Automobile                              Automobile   \n",
      "\n",
      "  Attribute Type       No of Instances             No of Attributes    Year  \n",
      "0  Multivariate        Classification   Categorical, Integer, Real    4177   \n",
      "1  Multivariate        Classification         Categorical, Integer   48842   \n",
      "2  Multivariate        Classification   Categorical, Integer, Real     798   \n",
      "3                 Recommender-Systems                  Categorical   37711   \n",
      "4  Multivariate        Classification   Categorical, Integer, Real     452   \n",
      "5  Multivariate        Classification   Categorical, Integer, Real    6000   \n",
      "6  Multivariate        Classification                  Categorical     226   \n",
      "7  Multivariate        Classification                  Categorical     226   \n",
      "8  Multivariate            Regression            Categorical, Real     398   \n",
      "9  Multivariate            Regression   Categorical, Integer, Real     205   \n"
     ]
    }
   ],
   "source": [
    "# Find all the dataset rows\n",
    "dataset_rows = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, \"//table[@border='1']/tbody/tr\"))\n",
    ")\n",
    "\n",
    "# Scrape the dataset details\n",
    "datasets = []\n",
    "counter = 0\n",
    "for row in dataset_rows:\n",
    "    if counter >= 10:\n",
    "        break\n",
    "\n",
    "    dataset_info = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    if len(dataset_info) >= 8:\n",
    "        dataset_name = dataset_info[0].text\n",
    "        data_type = dataset_info[1].text\n",
    "        task = dataset_info[2].text\n",
    "        attribute_type = dataset_info[3].text\n",
    "        no_of_instances = dataset_info[4].text\n",
    "        no_of_attributes = dataset_info[5].text\n",
    "        year = dataset_info[6].text\n",
    "\n",
    "        dataset = {\n",
    "            \"Dataset Name\": dataset_name,\n",
    "            \"Data Type\": data_type,\n",
    "            \"Task\": task,\n",
    "            \"Attribute Type\": attribute_type,\n",
    "            \"No of Instances\": no_of_instances,\n",
    "            \"No of Attributes\": no_of_attributes,\n",
    "            \"Year\": year\n",
    "        }\n",
    "        datasets.append(dataset)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(datasets)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77136129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****QUESTION NO 8 COMPLETE, ONLY SCRAPPED FIRST 10 RESULTS, not able to correct indexing****\n"
     ]
    }
   ],
   "source": [
    "print (\"*****QUESTION NO 8 COMPLETE, ONLY SCRAPPED FIRST 10 RESULTS, not able to correct indexing****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9450f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****QUESTION NO 9 - Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n"
     ]
    }
   ],
   "source": [
    "print(\"****QUESTION NO 9 - Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6d53547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open web\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\cws\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33bac0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending required input\n",
    "search=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "732000b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "search.button=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "search.button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6ca1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape Successful\n"
     ]
    }
   ],
   "source": [
    "# Scrape data\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "for page in range(start, end):\n",
    "    # Scrape names\n",
    "    try:\n",
    "        i_name_elements = driver.find_elements(By.XPATH, '//div[@class=\"outerRecSec\"]//div[@class=\"recSec fl fadeInUp\"]//span[@class=\"fl ellipsis\"]')\n",
    "        for element in i_name_elements:\n",
    "            Name.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('N/A')\n",
    "\n",
    "    # Scrape Designation\n",
    "    try:\n",
    "        desg_elements = driver.find_elements(By.XPATH, '//div[@class=\"outerRecSec\"]//div[@class=\"recSec fl fadeInUp\"]//span[@class=\"ellipsis clr\"]')\n",
    "        for element in desg_elements:\n",
    "            Designation.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        Designation.append('N/A')\n",
    "\n",
    "    # Scrape Company\n",
    "    try:\n",
    "        comp_elements = driver.find_elements(By.XPATH, '//div[@class=\"outerRecSec\"]//div[@class=\"recSec fl fadeInUp\"]//a[2]')\n",
    "        for element in comp_elements:\n",
    "            Company.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        Company.append('N/A')\n",
    "\n",
    "    # Scrape Skills\n",
    "    try:\n",
    "        sk_elements = driver.find_elements(By.XPATH, '//div[@class=\"outerRecSec\"]//div[@class=\"recSec fl fadeInUp\"]//div[@class=\"hireSec highlightable\"]')\n",
    "        for element in sk_elements:\n",
    "            Skills.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills.append('N/A')\n",
    "\n",
    "    # Scrape Location\n",
    "    try:\n",
    "        loc_elements = driver.find_elements(By.XPATH, '//div[@class=\"outerRecSec\"]//div[@class=\"recSec fl fadeInUp\"]//small[@class=\"ellipsis\"]')\n",
    "        for element in loc_elements:\n",
    "            Location.append(element.text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append('N/A')\n",
    "\n",
    "# Check lengths of lists and fill shorter lists with 'N/A'\n",
    "max_length = max(len(Name), len(Designation), len(Company), len(Skills), len(Location))\n",
    "Name += ['N/A'] * (max_length - len(Name))\n",
    "Designation += ['N/A'] * (max_length - len(Designation))\n",
    "Company += ['N/A'] * (max_length - len(Company))\n",
    "Skills += ['N/A'] * (max_length - len(Skills))\n",
    "Location += ['N/A'] * (max_length - len(Location))\n",
    "\n",
    "print(\"Scrape Successful\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffaeaae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Name        Designation  \\\n",
      "0                                   Aakash Harit         HR Manager   \n",
      "1                       MARSIAN Technologies LLP         Company HR   \n",
      "2                                   subhas patel        Founder CEO   \n",
      "3  Institute for Financial Management and Resear  Programme Manager   \n",
      "4                                  Asif Lucknowi           Director   \n",
      "\n",
      "                      Company  \\\n",
      "0        Data Science Network   \n",
      "1    MARSIAN Technologies LLP   \n",
      "2             LibraryXProject   \n",
      "3                        IFMR   \n",
      "4  Weupskill- Live Wire India   \n",
      "\n",
      "                                              Skills       Location  \n",
      "0  Classic ASP Developer, Internet Marketing Prof...          Delhi  \n",
      "1  Data Science, Artificial Intelligence, Machine...           Pune  \n",
      "2  Hadoop, Spark, Digital Strategy, Data Architec...  UK - (london)  \n",
      "3                                       Data Science        Chennai  \n",
      "4  Technical Training, Software Development, Pres...         Indore  \n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Name': Name,\n",
    "    'Designation': Designation,\n",
    "    'Company': Company,\n",
    "    'Skills': Skills,\n",
    "    'Location': Location\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "380ce0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name        Designation  \\\n",
       "0                                   Aakash Harit         HR Manager   \n",
       "1                       MARSIAN Technologies LLP         Company HR   \n",
       "2                                   subhas patel        Founder CEO   \n",
       "3  Institute for Financial Management and Resear  Programme Manager   \n",
       "4                                  Asif Lucknowi           Director   \n",
       "\n",
       "                      Company       Location  \\\n",
       "0        Data Science Network          Delhi   \n",
       "1    MARSIAN Technologies LLP           Pune   \n",
       "2             LibraryXProject  UK - (london)   \n",
       "3                        IFMR        Chennai   \n",
       "4  Weupskill- Live Wire India         Indore   \n",
       "\n",
       "                                              Skills  \n",
       "0  Classic ASP Developer, Internet Marketing Prof...  \n",
       "1  Data Science, Artificial Intelligence, Machine...  \n",
       "2  Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "3                                       Data Science  \n",
       "4  Technical Training, Software Development, Pres...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'Name':Name,'Designation':Designation,'Company':Company,'Location':Location,'Skills':Skills})\n",
    "#check first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c156bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****END OF QUESTION 9*******\n",
      "*****END OF WEB SCRAPPING ASSIGNMENT NO 4\n"
     ]
    }
   ],
   "source": [
    "print (\"****END OF QUESTION 9*******\")\n",
    "print (\"*****END OF WEB SCRAPPING ASSIGNMENT NO 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9da6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
